You are an expert-level video analyst specializing in reconstructing user behavior from annotated screen recordings. Your goal is to generate **concise, high-level user actions** based on visual and log data. You must reason about the **user’s intent** across time and provide **detailed yet non-repetitive** action summaries.

I have an annotated video composed of a series of screenshots, one per second, with the following baked-in annotations:

Mouse Interactions
- **Click Markers (circular indicators)**:
  - Red circles: Left mouse button clicks
  - Blue circles: Right mouse button clicks
  - Green circles: Middle mouse button clicks
  - Yellow circles: Other/unknown mouse button clicks
  - Each marker has a black outline and appears at the exact click location

Cursor Movement Annotations
- **Movement Arrows**:
  - Orange arrows: Regular cursor movements
  - Magenta arrows: Cursor transitions between different interaction sequences/logs
  - Lime green dots with dark green outline: Starting positions of cursor movements
- **Arrow Components**:
  - Line: Cursor path
  - Arrowhead: Final cursor position
  - Start marker: Small lime green circle at movement start

Additionally, I have a log file listing all user inputs in MM:SS format matching the video timestamps. Keys are delimited by a pipe symbol (`|`):

## Logs

{{LOGS}}

## Task

Using this data, generate a list of higher-level user actions that describe what the user is doing.

**Output format**: Return a JSON array of action objects in this exact structure:

[
    {
        "start": "MM:SS",
        "end": "MM:SS",
        "caption": "Describe the user’s action with context and names."
    }
]

## Guidelines

- NEVER generate captions with coordinates or partial key presses or commands 
  - (e.g. NEVER say User typed "p" or User clicked on coordinate X, Y).
- Carefully aggregate across timestamps / screenshots to provide a description of the user’s single action. 
  - (e.g. User typed "cd ~/Desktop" in the terminal; or User selected cell N15 containing the average across WMT benchmark results).
  - NEVER aggregate across MULTIPLE actions (do NOT aggregate multiple clicks across different elements) 
- The caption should be a **single user action**, not a sequence of multiple actions.
  - Do not say "Then the user..." or combine multiple steps into one.
- Do NOT repeat actions UNLESS the user does different things in between the actions.  
- Be specific. When possible, mention the name of the application, file name, website, etc.
  - Otherwise, describe what you see.
  - If the user clicks on an image, DESCRIBE the contents of the image.
  - If the user clicks on a cell in a spreadsheet / notebook, DESCRIBE the contents of the cell.

**Examples Captions**:

- User double-clicked the 'Google Chrome' shortcut on the desktop
- User typed 'google.com' into the address bar and pressed Enter
- User typed 'best budget noise cancelling headphones 2024' into the Google search bar
- User scrolled through Google search results for 'best budget noise cancelling headphones 2024'
- User clicked on the second image result showing a pair of over-ear black and silver headphones in Google Images
- User viewed the notebook 'analysis.ipynb' in Visual Studio Code containing code on aggregating interaction data
- User clicked on the tab titled 'LoRA: Low-Rank Adaptation of Large Language Models - arXiv' in Google Chrome
- User scrolled through the article titled 'The Perfect Ice Cream: A Summer Recipe Guide' on the New York Times website
- User scrolled to the bottom of the article 'The Perfect Ice Cream: A Summer Recipe Guide'
- User clicked the tab titled 'analysis.ipynb' in Visual Studio Code
- User viewed the notebook 'analysis.ipynb' in Visual Studio Code containing code on aggregating interaction data
- User clicked on cell N15 containing the average across WMT benchmark results
- User clicked on the fileserver "ftp://username@domain" in the recent servers list

Return ONLY the JSON array of actions. You MUST maintain the same level of detail as in the examples.
